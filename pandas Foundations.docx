1. Data ingestion & inspection
- Inspecting your data
    df.head() and df.tail(3)

- DataFrame data types
    Your job is to use df.info() to determine information about the total count of non-null entries and infer the total count of null entries, which likely indicates missing data.
 
- NumPy and pandas working together
    # Import numpy
    import numpy as np

    # Create array of DataFrame values: np_vals
    np_vals = df.values

    # Create new array of base 10 logarithm values: np_vals_log10
    np_vals_log10 = np.log10(np_vals)

    # Create array of new DataFrame by passing df to np.log10(): df_log10
    df_log10 = np.log10(df)

    # Print original and new data containers
    [print(x, 'has type', type(eval(x))) for x in ['np_vals', 'np_vals_log10', 'df', 'df_log10']]

- Zip lists to build a DataFrame
    # Zip the 2 lists together into one list of (key,value) tuples: zipped
    zipped = list(zip(list_keys,list_values))

    # Inspect the list using print()
    print(zipped)

    # Build a dictionary with the zipped list: data
    data = dict(zipped)

    # Build and inspect a DataFrame from the dictionary: df
    df = pd.DataFrame(data)
    print(df)

- Labeling your data
    # Build a list of labels: list_labels
    list_labels = ['year', 'artist', 'song', 'chart weeks']

    # Assign the list of labels to the columns attribute: df.columns
    df.columns = list_labels

- Building DataFrames with broadcasting
    # Make a string with the value 'PA': state
    state = 'PA'

    # Construct a dictionary: data
    data = {'state':state, 'city':cities}

    # Construct a DataFrame from dictionary data: df
    df = pd.DataFrame(data)

    # Print the DataFrame
    print(df)

- Reading a flat file
    # Read in the file: df1
    df1 = pd.read_csv(data_file)

    # Create a list of the new column labels: new_labels
    new_labels = ['year', 'population']

    # Read in the file, specifying the header and names parameters: df2
    df2 = pd.read_csv(data_file, header=0, names=new_labels)

    # Print both the DataFrames
    print(df1)
    print(df2)

- Delimiters, headers, and extensions
    # Read the raw file as-is: df1
    df1 = pd.read_csv(file_messy)

    # Print the output of df1.head()
    print(df1.head())

    # Read in the file with the correct parameters: df2
    df2 = pd.read_csv(file_messy, delimiter=' ', header=3, comment='#')

    # Print the output of df2.head()
    print(df2.head())

    # Save the cleaned up DataFrame to a CSV file without the index
    df2.to_csv(file_clean, index=False)

    # Save the cleaned up DataFrame to an excel file without the index
    df2.to_excel('file_clean.xlsx', index=False)

- Plotting series using pandas (pandas.core.frame.DataFrame)
    # Create a plot with color='red'
    df.plot(color='red')

    # Add a title
    plt.title('Temperature in Austin')

    # Specify the x-axis label
    plt.xlabel('Hours since midnight August 1, 2010')

    # Specify the y-axis label
    plt.ylabel('Temperature (degrees F)')

    # Display the plot
    plt.show()

- Plotting DataFrames
    # Plot all columns (default)
    df.plot()
    plt.show()

    # Plot all columns as subplots
    df.plot(subplots=True)
    plt.show()

    # Plot just the Dew Point data
    column_list1 = ['Dew Point (deg F)']
    df[column_list1].plot()
    plt.show()

    # Plot the Dew Point and Temperature data, but not the Pressure data
    column_list2 = ['Temperature (deg F)','Dew Point (deg F)']
    df[column_list2].plot()
    plt.show()

3. Exploratory data analysis
- pandas line plots
    # Create a list of y-axis column names: y_columns
    y_columns = ['AAPL', 'IBM']

    # Generate a line plot
    df.plot(x='Month', y=y_columns)

    # Add the title
    plt.title('Monthly stock prices')

    # Add the y-axis label
    plt.ylabel('Price ($US)')

    # Display the plot
    plt.show()

- pandas scatter plots
    # Generate a scatter plot
    df.plot(kind='scatter', x='hp', y='mpg', s=sizes)

    # Add the title
    plt.title('Fuel efficiency vs Horse-power')

    # Add the x-axis label
    plt.xlabel('Horse-power')

    # Add the y-axis label
    plt.ylabel('Fuel efficiency (mpg)')

    # Display the plot
    plt.show()

- pandas box plots
    # Make a list of the column names to be plotted: cols
    cols = ['weight','mpg']

    # Generate the box plots
    df[cols].plot(kind='box',subplots=True)

    # Display the plot
    plt.show()

- pandas hist, pdf and cdf
    # This formats the plots such that they appear on separate rows
    fig, axes = plt.subplots(nrows=2, ncols=1)

    # Plot the PDF
    df.fraction.plot(ax=axes[0], kind='hist', normed=True, bins=30, range=(0,.3))
    plt.show()

    # Plot the CDF
    df.fraction.plot(ax=axes[1], kind='hist', normed=True, bins=30, cumulative=True, range=(0,.3))
    plt.show()

- Bachelor's degrees awarded to women
    # Print the minimum value of the Engineering column
    print(df['Engineering'].min())

    # Print the maximum value of the Engineering column
    print(df['Engineering'].max())

    # Construct the mean percentage per year: mean
    mean = df.mean(axis='columns')

    # Plot the average percentage per year
    mean.plot()

    # Display the plot
    plt.show()

- Median vs mean
    # Print summary statistics of the fare column with .describe()
    print(df.fare.describe())

    # Generate a box plot of the fare column
    df['fare'].plot(kind='box')

    # Show the plot
    plt.show()

- Quantiles
    # Print the number of countries reported in 2015
    print(df['2015'].count())

    # Print the 5th and 95th percentiles
    print(df.quantile([0.05, 0.95]))

    # Generate a box plot
    years = ['1800','1850','1900','1950','2000']
    df[years].plot(kind='box')
    plt.show()

- Standard deviation of temperature
    # Print the mean of the January and March data
    print(january.mean(), march.mean())

    # Print the standard deviation of the January and March data
    print(january.std(), march.std())

- Filtering and counting
    How many automobiles were manufactured in Asia in the automobile dataset? The DataFrame has been provided for you as df. Use filtering and the .count() member method to determine the number of rows where the 'origin' column has the value 'Asia'.

    As an example, you can extract the rows that contain 'US' as the country of origin using df[df['origin'] == 'US']

- Separate and summarize
    # Compute the global mean and global standard deviation: global_mean, global_std
    global_mean = df.mean()
    global_std = df.std()

    # Filter the US population from the origin column: us
    us = df[df['origin'] =='US']

    # Compute the US mean and US standard deviation: us_mean, us_std
    us_mean = us.mean()
    us_std = us.std()

    # Print the differences
    print(us_mean - global_mean)
    print(us_std - global_std)

- Separate and plot
    # Display the box plots on 3 separate rows and 1 column
    fig, axes = plt.subplots(nrows=3, ncols=1)

    # Generate a box plot of the fare prices for the First passenger class
    titanic.loc[titanic['pclass'] == 1].plot(ax=axes[0], y='fare', kind='box')

    # Generate a box plot of the fare prices for the Second passenger class
    titanic.loc[titanic['pclass'] == 2].plot(ax=axes[1], y='fare', kind='box')

    # Generate a box plot of the fare prices for the Third passenger class
    titanic.loc[titanic['pclass'] == 3].plot(ax=axes[2], y='fare', kind='box')

    # Display the plot
    plt.show()

- Reading in a data file
    # Import pandas
    import pandas as pd

    # Read in the data file: df
    df = pd.read_csv(data_file)

    # Print the output of df.head()
    print(df.head())

    # Read in the data file with header=None: df_headers
    df_headers = pd.read_csv(data_file, header=None)

    # Print the output of df_headers.head()
    print(df_headers.head())

- Re-assigning column names
    # Split on the comma to create a list: column_labels_list
    column_labels_list = column_labels.split(',')

    # Assign the new column labels to the DataFrame: df.columns
    df.columns = column_labels_list

    # Remove the appropriate columns: df_dropped
    df_dropped = df.drop(list_to_drop, axis='columns')

    # Print the output of df_dropped.head()
    print(df_dropped.head())

- Cleaning and tidying datetime data
    # Convert the date column to string: df_dropped['date']
    df_dropped['date'] = df_dropped.date.astype(str)

    # Pad leading zeros to the Time column: df_dropped['Time']
    df_dropped['Time'] = df_dropped['Time'].apply(lambda x:'{:0>4}'.format(x))

    # Concatenate the new date and Time columns: date_string
    date_string = df_dropped.date+df_dropped.Time

    # Convert the date_string Series to datetime: date_times
    date_times = pd.to_datetime(date_string, format='%Y%m%d%H%M')

    # Set the index to be the new date_times container: df_clean
    df_clean = df_dropped.set_index(date_times)

    # Print the output of df_clean.head()
    print(df_clean.head())

- Cleaning the numeric columns
    # Print the dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011
    print(df_clean.loc['2011-06-20 08:00:00':'2011-06-20 09:00:00', 'dry_bulb_faren'])

    # Convert the dry_bulb_faren column to numeric values: df_clean['dry_bulb_faren']
    df_clean['dry_bulb_faren'] = pd.to_numeric(df_clean['dry_bulb_faren'], errors='coerce')

    # Print the transformed dry_bulb_faren temperature between 8 AM and 9 AM on June 20, 2011
    print(df_clean.loc['2011-06-20 08:00:00':'2011-06-20 09:00:00', 'dry_bulb_faren'])

    # Convert the wind_speed and dew_point_faren columns to numeric values
    df_clean['wind_speed'] = pd.to_numeric(df_clean['wind_speed'], errors='coerce')
    df_clean['dew_point_faren'] = pd.to_numeric(df_clean['dew_point_faren'], errors='coerce')

- Signal min, max, median
    # Print the median of the dry_bulb_faren column
    print(df_clean['dry_bulb_faren'].median())

    # Print the median of the dry_bulb_faren column for the time range '2011-Apr':'2011-Jun'
    print(df_clean.loc['2011-Apr':'2011-Jun', 'dry_bulb_faren'].median())

    # Print the median of the dry_bulb_faren column for the month of January
    print(df_clean.loc['2011-Jan', 'dry_bulb_faren'].median())

- Signal variance
    # Downsample df_clean by day and aggregate by mean: daily_mean_2011
    daily_mean_2011 = df_clean.resample('D').mean()

    # Extract the dry_bulb_faren column from daily_mean_2011 using .values: daily_temp_2011
    daily_temp_2011 = daily_mean_2011['dry_bulb_faren'].values

    # Downsample df_climate by day and aggregate by mean: daily_climate
    daily_climate = df_climate.resample('D').mean()

    # Extract the Temperature column from daily_climate using .reset_index(): daily_temp_climate
    daily_temp_climate = daily_climate.reset_index()['Temperature']

    # Compute the difference between the two arrays and print the mean difference
    difference = daily_temp_2011 - daily_temp_climate
    print(difference.mean())

- Sunny or cloudy 1
    # Using df_clean, when is sky_condition 'CLR'?
    is_sky_clear = df_clean['sky_condition']=='CLR'

    # Filter df_clean using is_sky_clear
    sunny = df_clean.loc[is_sky_clear]

    # Resample sunny by day then calculate the max
    sunny_daily_max = sunny.resample('D').max()

    # See the result
    sunny_daily_max.head()

- Sunny or cloudy 2
    # Using df_clean, when does sky_condition contain 'OVC'?
    is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')

    # Filter df_clean using is_sky_overcast
    overcast = df_clean.loc[is_sky_overcast]

    # Resample overcast by day then calculate the max
    overcast_daily_max = overcast.resample('D').max()

    # See the result
    overcast_daily_max.head()

- Sunny or cloudy 3 
    # From previous steps
    is_sky_clear = df_clean['sky_condition']=='CLR'
    sunny = df_clean.loc[is_sky_clear]
    sunny_daily_max = sunny.resample('D').max()
    is_sky_overcast = df_clean['sky_condition'].str.contains('OVC')
    overcast = df_clean.loc[is_sky_overcast]
    overcast_daily_max = overcast.resample('D').max()

    # Calculate the mean of sunny_daily_max
    sunny_daily_max_mean = sunny_daily_max.mean()

    # Calculate the mean of overcast_daily_max
    overcast_daily_max_mean = overcast_daily_max.mean()

    # Print the difference (sunny minus overcast)
    print(sunny_daily_max_mean-overcast_daily_max_mean)

- Weekly average temperature and visibility
    # Import matplotlib.pyplot as plt
    import matplotlib.pyplot as plt

    # Select the visibility and dry_bulb_faren columns and resample them: weekly_mean
    weekly_mean = df_clean[['visibility','dry_bulb_faren']].resample('W').mean()

    # Print the output of weekly_mean.corr()
    print(weekly_mean.corr())

    # Plot weekly_mean with subplots=True
    weekly_mean.plot(subplots=True)
    plt.show()

- Daily hours of clear sky 1
    # Using df_clean, when is sky_condition 'CLR'?
    is_sky_clear = df_clean['sky_condition'] == 'CLR'

    # Resample is_sky_clear by day
    resampled = is_sky_clear.resample('D')

    # See the result
    resampled

- Daily hours of clear sky 2
    # From previous step
    is_sky_clear = df_clean['sky_condition'] == 'CLR'
    resampled = is_sky_clear.resample('D')

    # Calculate the number of sunny hours per day
    sunny_hours = resampled.sum()

    # Calculate the number of measured hours per day
    total_hours = resampled.count()

    # Calculate the fraction of hours per day that were sunny
    sunny_fraction = sunny_hours/total_hours

- Daily hours of clear sky 3
    # From previous steps
    is_sky_clear = df_clean['sky_condition'] == 'CLR'
    resampled = is_sky_clear.resample('D')
    sunny_hours = resampled.sum()
    total_hours = resampled.count()
    sunny_fraction = sunny_hours / total_hours

    # Make a box plot of sunny_fraction
    sunny_fraction.plot(kind='box')
    plt.show()

- Heat or humidity
    # Resample dew_point_faren and dry_bulb_faren by Month, aggregating the maximum values: monthly_max
    monthly_max = df_clean[['dew_point_faren','dry_bulb_faren']].resample('M').max()

    # Generate a histogram with bins=8, alpha=0.5, subplots=True
    monthly_max.plot(kind = 'hist',bins=8,alpha=0.5, subplots=True)

    # Show the plot
    plt.show()

- Probability of high temperatures
    # Extract the maximum temperature in August 2010 from df_climate: august_max
    august_max = df_climate.loc['2010-08','Temperature'].max()
    print(august_max)

    # Resample August 2011 temps in df_clean by day & aggregate the max value: august_2011
    august_2011 = df_clean.loc['2011-08','dry_bulb_faren'].resample('D').max()

    # Filter for days in august_2011 where the value exceeds august_max: august_2011_high
    august_2011_high = august_2011[august_2011 > august_max]

    # Construct a CDF of august_2011_high
    august_2011_high.plot(kind='hist', normed=True, cumulative=True, bins=25)

    # Display the plot
    plt.show()
























